{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f356841-2abb-4554-800c-046eb7e8a860",
   "metadata": {},
   "source": [
    "# Multiple Regressions and Assumptions of Regression\n",
    "By Adrian Chavez-Loya\n",
    "\n",
    "## Background\n",
    "The US Department of Agriculture (USDA) publishes county-level datasets on poverty, population, unemployment, income and Education (https://www.ers.usda.gov/data-products/county-level-data-sets/). Imagine you're working for the USDA as a Data Scientist and you've been tasked with putting together an analysis of the influence of education, in rural vs urban communities, on household income and unemployment.\n",
    "\n",
    "The USDA defines the rural vs urban on a continuum from 1 to 9 with 1 referring to the largest counties (for reference, Cache Valley was listed as a 3 in 2013). The full scale is shown below:\n",
    "\n",
    "1. Metro - Counties in metro areas of 1 million population or more                                               \n",
    "2. Metro - Counties in metro areas of 250,000 to 1 million population                                                   \n",
    "3. Metro - Counties in metro areas of fewer than 250,000 population                                                     \n",
    "4. Nonmetro - Urban population of 20,000 or more, adjacent to a metro area                                             \n",
    "5. Nonmetro - Urban population of 20,000 or more, not adjacent to a metro area                                         \n",
    "6. Nonmetro - Urban population of 2,500 to 19,999, adjacent to a metro area                                             \n",
    "7. Nonmetro - Urban population of 2,500 to 19,999, not adjacent to a metro area                                         \n",
    "8. Nonmetro - Completely rural or less than 2,500 urban population, adjacent to a metro area                           \n",
    "9. Nonmetro - Completely rural or less than 2,500 urban population, not adjacent to a metro area\n",
    "\n",
    "**Relevant Datasets**\n",
    "In the `education_unemployment` folder:\n",
    "* `education.csv`\n",
    "* `unemployment.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deaf324-951e-434f-8e04-36d3b72118a7",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Merge these two datasets on the FIPS code for each county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c2f99c1a-1c17-43ce-8d88-88a62e6fd3a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS Code</th>\n",
       "      <th>State_x</th>\n",
       "      <th>Area name</th>\n",
       "      <th>2003 Rural-urban Continuum Code</th>\n",
       "      <th>2003 Urban Influence Code</th>\n",
       "      <th>2013 Rural-urban Continuum Code</th>\n",
       "      <th>2013 Urban Influence Code</th>\n",
       "      <th>City/Suburb/Town/Rural 2013</th>\n",
       "      <th>Less than a high school diploma, 1970</th>\n",
       "      <th>High school diploma only, 1970</th>\n",
       "      <th>...</th>\n",
       "      <th>Civilian_labor_force_2019</th>\n",
       "      <th>Employed_2019</th>\n",
       "      <th>Unemployed_2019</th>\n",
       "      <th>Unemployment_rate_2019</th>\n",
       "      <th>Civilian_labor_force_2020</th>\n",
       "      <th>Employed_2020</th>\n",
       "      <th>Unemployed_2020</th>\n",
       "      <th>Unemployment_rate_2020</th>\n",
       "      <th>Median_Household_Income_2019</th>\n",
       "      <th>Med_HH_Income_Percent_of_State_Total_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1007</td>\n",
       "      <td>AL</td>\n",
       "      <td>Bibb County</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>City</td>\n",
       "      <td>5,272</td>\n",
       "      <td>1,402</td>\n",
       "      <td>...</td>\n",
       "      <td>8,639</td>\n",
       "      <td>8,371</td>\n",
       "      <td>268</td>\n",
       "      <td>3.1</td>\n",
       "      <td>8,640</td>\n",
       "      <td>8,067</td>\n",
       "      <td>573</td>\n",
       "      <td>6.6</td>\n",
       "      <td>47,918</td>\n",
       "      <td>92.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1009</td>\n",
       "      <td>AL</td>\n",
       "      <td>Blount County</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>City</td>\n",
       "      <td>10,677</td>\n",
       "      <td>3,440</td>\n",
       "      <td>...</td>\n",
       "      <td>25,196</td>\n",
       "      <td>24,516</td>\n",
       "      <td>680</td>\n",
       "      <td>2.7</td>\n",
       "      <td>24,661</td>\n",
       "      <td>23,653</td>\n",
       "      <td>1,008</td>\n",
       "      <td>4.1</td>\n",
       "      <td>52,902</td>\n",
       "      <td>102.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1021</td>\n",
       "      <td>AL</td>\n",
       "      <td>Chilton County</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>City</td>\n",
       "      <td>10,285</td>\n",
       "      <td>2,805</td>\n",
       "      <td>...</td>\n",
       "      <td>19,841</td>\n",
       "      <td>19,296</td>\n",
       "      <td>545</td>\n",
       "      <td>2.7</td>\n",
       "      <td>19,592</td>\n",
       "      <td>18,618</td>\n",
       "      <td>974</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49,692</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1073</td>\n",
       "      <td>AL</td>\n",
       "      <td>Jefferson County</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>City</td>\n",
       "      <td>186,882</td>\n",
       "      <td>101,656</td>\n",
       "      <td>...</td>\n",
       "      <td>316,802</td>\n",
       "      <td>307,648</td>\n",
       "      <td>9,154</td>\n",
       "      <td>2.9</td>\n",
       "      <td>315,957</td>\n",
       "      <td>296,282</td>\n",
       "      <td>19,675</td>\n",
       "      <td>6.2</td>\n",
       "      <td>54,127</td>\n",
       "      <td>104.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1115</td>\n",
       "      <td>AL</td>\n",
       "      <td>St. Clair County</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>City</td>\n",
       "      <td>10,304</td>\n",
       "      <td>3,540</td>\n",
       "      <td>...</td>\n",
       "      <td>40,698</td>\n",
       "      <td>39,591</td>\n",
       "      <td>1,107</td>\n",
       "      <td>2.7</td>\n",
       "      <td>40,132</td>\n",
       "      <td>38,146</td>\n",
       "      <td>1,986</td>\n",
       "      <td>4.9</td>\n",
       "      <td>65,403</td>\n",
       "      <td>126.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FIPS Code State_x         Area name  2003 Rural-urban Continuum Code  \\\n",
       "0       1007      AL       Bibb County                              1.0   \n",
       "1       1009      AL     Blount County                              1.0   \n",
       "2       1021      AL    Chilton County                              1.0   \n",
       "3       1073      AL  Jefferson County                              1.0   \n",
       "4       1115      AL  St. Clair County                              1.0   \n",
       "\n",
       "   2003 Urban Influence Code  2013 Rural-urban Continuum Code  \\\n",
       "0                        1.0                              1.0   \n",
       "1                        1.0                              1.0   \n",
       "2                        1.0                              1.0   \n",
       "3                        1.0                              1.0   \n",
       "4                        1.0                              1.0   \n",
       "\n",
       "   2013 Urban Influence Code City/Suburb/Town/Rural 2013  \\\n",
       "0                        1.0                        City   \n",
       "1                        1.0                        City   \n",
       "2                        1.0                        City   \n",
       "3                        1.0                        City   \n",
       "4                        1.0                        City   \n",
       "\n",
       "  Less than a high school diploma, 1970 High school diploma only, 1970  ...  \\\n",
       "0                                 5,272                          1,402  ...   \n",
       "1                                10,677                          3,440  ...   \n",
       "2                                10,285                          2,805  ...   \n",
       "3                               186,882                        101,656  ...   \n",
       "4                                10,304                          3,540  ...   \n",
       "\n",
       "  Civilian_labor_force_2019 Employed_2019  Unemployed_2019  \\\n",
       "0                     8,639         8,371              268   \n",
       "1                    25,196        24,516              680   \n",
       "2                    19,841        19,296              545   \n",
       "3                   316,802       307,648            9,154   \n",
       "4                    40,698        39,591            1,107   \n",
       "\n",
       "   Unemployment_rate_2019  Civilian_labor_force_2020  Employed_2020  \\\n",
       "0                     3.1                      8,640          8,067   \n",
       "1                     2.7                     24,661         23,653   \n",
       "2                     2.7                     19,592         18,618   \n",
       "3                     2.9                    315,957        296,282   \n",
       "4                     2.7                     40,132         38,146   \n",
       "\n",
       "  Unemployed_2020 Unemployment_rate_2020 Median_Household_Income_2019  \\\n",
       "0             573                    6.6                       47,918   \n",
       "1           1,008                    4.1                       52,902   \n",
       "2             974                    5.0                       49,692   \n",
       "3          19,675                    6.2                       54,127   \n",
       "4           1,986                    4.9                       65,403   \n",
       "\n",
       "  Med_HH_Income_Percent_of_State_Total_2019  \n",
       "0                                      92.6  \n",
       "1                                     102.2  \n",
       "2                                      96.0  \n",
       "3                                     104.6  \n",
       "4                                     126.3  \n",
       "\n",
       "[5 rows x 141 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# read data sets\n",
    "education = pd.read_csv('/Users/adrianchavezloya/Desktop/Summer 2024/Intro to Regression:Machine Learning/Module 1 and 2/HW2_Multiple_Regression/education.csv')\n",
    "unemployment = pd.read_csv('/Users/adrianchavezloya/Desktop/Summer 2024/Intro to Regression:Machine Learning/Module 1 and 2/HW2_Multiple_Regression/unemployment.csv')\n",
    "\n",
    "# merge data sets (using FIPS code) \n",
    "merged_data = education.merge(unemployment, left_on='FIPS Code', right_on='FIPS_Code')\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb85ad-262b-45cf-8665-1bb742de244e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 2\n",
    "Using this merged dataset, fit a model that predicts household income given the different variables of percent of the county reaching the different education levels. I'll leave it up to you how you decide to include the rural vs urban in your model (e.g. as a continuous variable, as a categorical variable, as a binary variable, by subsetting).\n",
    "\n",
    "Tip: Does it make sense to include every level in the model from a mathematical perspective?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fd9ed7-781a-4b14-8862-3def0d48fc27",
   "metadata": {
    "tags": []
   },
   "source": [
    "**To avoid multicollinearity when considering rural vs urban continuum as categorical variables by using a dummy/dropping one level. There may also be interactions between education levels**\n",
    "\n",
    "* I will test different models to see if there is indeed overfitting due to including all the levels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f81010e-9a44-4287-b5ea-2600ba22df55",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "**Independent Variables:**\n",
    "\n",
    "* 'Less than a high school diploma, 1970'\n",
    "\n",
    "* 'High school diploma only, 1970'\n",
    "\n",
    "* 'City/Suburb/Town/Rural 2013' (one-hot encoded: Rural, Suburb, Town)\n",
    "\n",
    "\n",
    "**Dependent Variable:**\n",
    "\n",
    "* 'Median_Household_Income_2019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "0648eb40-4f87-40a8-ab33-99c104fb5ff3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS model with original dataset:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.217\n",
      "Model:                            OLS   Adj. R-squared:                  0.216\n",
      "Method:                 Least Squares   F-statistic:                     176.4\n",
      "Date:                Sat, 01 Jun 2024   Prob (F-statistic):          4.09e-166\n",
      "Time:                        14:47:46   Log-Likelihood:                -34734.\n",
      "No. Observations:                3193   AIC:                         6.948e+04\n",
      "Df Residuals:                    3187   BIC:                         6.952e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       6.404e+04    369.212    173.440      0.000    6.33e+04    6.48e+04\n",
      "x1            -0.0388      0.005     -7.560      0.000      -0.049      -0.029\n",
      "x2             0.0595      0.008      7.591      0.000       0.044       0.075\n",
      "x3         -1.396e+04    550.152    -25.379      0.000    -1.5e+04   -1.29e+04\n",
      "x4         -1.113e+04    761.111    -14.627      0.000   -1.26e+04   -9640.554\n",
      "x5          -1.32e+04    636.574    -20.740      0.000   -1.45e+04    -1.2e+04\n",
      "==============================================================================\n",
      "Omnibus:                      720.712   Durbin-Watson:                   1.214\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2076.975\n",
      "Skew:                           1.169   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.186   Cond. No.                     4.49e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.49e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "VIF for original dataset:\n",
      "                                Variable         VIF\n",
      "0                                  const    2.641400\n",
      "1  Less than a high school diploma, 1970  455.948083\n",
      "2         High school diploma only, 1970  456.025669\n",
      "3      City/Suburb/Town/Rural 2013_Rural    1.255282\n",
      "4     City/Suburb/Town/Rural 2013_Suburb    1.155385\n",
      "5       City/Suburb/Town/Rural 2013_Town    1.218045\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Extract relevant columns\n",
    "data = merged_data[['Less than a high school diploma, 1970', \n",
    "                    'High school diploma only, 1970', \n",
    "                    'Median_Household_Income_2019',\n",
    "                    'City/Suburb/Town/Rural 2013']]\n",
    "\n",
    "# One-hot encode the 'City/Suburb/Town/Rural 2013' column\n",
    "data = pd.get_dummies(data, columns=['City/Suburb/Town/Rural 2013'], drop_first=True)\n",
    "\n",
    "# Remove commas from numerical values in the DataFrame\n",
    "data = data.replace({',': ''}, regex=True)\n",
    "\n",
    "# Convert dependent variable to numeric and handle errors\n",
    "data['Median_Household_Income_2019'] = pd.to_numeric(data['Median_Household_Income_2019'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in the dependent variable\n",
    "data = data.dropna(subset=['Median_Household_Income_2019'])\n",
    "\n",
    "# Define independent and dependent variables as numpy arrays\n",
    "X = data.drop(columns=['Median_Household_Income_2019']).values\n",
    "y = data['Median_Household_Income_2019'].values\n",
    "\n",
    "# Convert array to float\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)\n",
    "\n",
    "# Identify and replace infinite values with NaN\n",
    "X[~np.isfinite(X)] = np.nan\n",
    "\n",
    "# Impute missing values (NaN) with mean\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "X = mean_imputer.fit_transform(X)\n",
    "\n",
    "# Add constant to independent variables for intercept term\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the OLS model\n",
    "ols_model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print summary of the model\n",
    "print(\"OLS model with original dataset:\")\n",
    "print(ols_model.summary())\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "X_df = pd.DataFrame(X, columns=['const'] + list(data.drop(columns=['Median_Household_Income_2019']).columns))\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Variable\"] = X_df.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X_df.values, i) for i in range(X_df.shape[1])]\n",
    "\n",
    "print(\"VIF for original dataset:\")\n",
    "print(vif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6441735d-ea50-4600-ba81-6429c8cd33f7",
   "metadata": {},
   "source": [
    "The R-squared values of the models are around 0.217, indicating that the models explain about 21.7% of the variance in household income. While this is not a very high R-squared value, it does suggest some explanatory power. However, there are likely other factors influencing household income that are not captured by these models.\n",
    "\n",
    "# Regression Assumptions:\n",
    "Multicollinearity: The high VIF values for 'Less than a high school diploma, 1970' and 'High school diploma only, 1970' in Models 1 and 3 indicate severe multicollinearity, which is a violation of the regression assumptions.\n",
    "\n",
    "Normality of Errors: The Omnibus and Jarque-Bera tests indicate that the residuals are not normally distributed (Prob (Omnibus) and Prob (JB) are 0.000), which is another assumption violation.\n",
    "\n",
    "Linearity: The linear relationship assumption might be violated if there are significant nonlinear relationships between the predictors and the response variable that are not captured by the model.\n",
    "\n",
    "Homoscedasticity: The assumption of constant variance of errors might be violated, as indicated by the Durbin-Watson statistic being far from 2 (around 1.2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583ba208-3c28-4312-910b-5c2dced2c9aa",
   "metadata": {},
   "source": [
    "# Model 2: OLS Model with Reduced Dataset (Removed 'High school diploma only, 1970')\n",
    "**Variables:**\n",
    "\n",
    "Independent Variables:\n",
    "\n",
    "* 'Less than a high school diploma, 1970'\n",
    "\n",
    "* 'City/Suburb/Town/Rural 2013' (one-hot encoded: Rural, Suburb, Town)\n",
    "\n",
    "Dependent Variable:\n",
    "\n",
    "* 'Median_Household_Income_2019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1e323e03-e8de-4776-8e6c-4c241ee7b0c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS model with reduced dataset:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.203\n",
      "Model:                            OLS   Adj. R-squared:                  0.202\n",
      "Method:                 Least Squares   F-statistic:                     202.5\n",
      "Date:                Sat, 01 Jun 2024   Prob (F-statistic):          6.13e-155\n",
      "Time:                        14:49:27   Log-Likelihood:                -34762.\n",
      "No. Observations:                3193   AIC:                         6.953e+04\n",
      "Df Residuals:                    3188   BIC:                         6.956e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        6.41e+04    372.365    172.155      0.000    6.34e+04    6.48e+04\n",
      "x1             0.0001      0.000      0.477      0.634      -0.000       0.001\n",
      "x2         -1.407e+04    554.828    -25.361      0.000   -1.52e+04    -1.3e+04\n",
      "x3         -1.125e+04    767.689    -14.651      0.000   -1.28e+04   -9742.126\n",
      "x4         -1.332e+04    641.997    -20.755      0.000   -1.46e+04   -1.21e+04\n",
      "==============================================================================\n",
      "Omnibus:                      739.991   Durbin-Watson:                   1.204\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2177.631\n",
      "Skew:                           1.192   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.269   Cond. No.                     3.76e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.76e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "VIF for reduced dataset:\n",
      "                                Variable       VIF\n",
      "0                                  const  2.639828\n",
      "1  Less than a high school diploma, 1970  1.003449\n",
      "2      City/Suburb/Town/Rural 2013_Rural  1.254436\n",
      "3     City/Suburb/Town/Rural 2013_Suburb  1.154932\n",
      "4       City/Suburb/Town/Rural 2013_Town  1.217268\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Extract relevant columns, removing one of the highly correlated variables\n",
    "data = merged_data[['Less than a high school diploma, 1970', \n",
    "                    'Median_Household_Income_2019',\n",
    "                    'City/Suburb/Town/Rural 2013']]\n",
    "\n",
    "# One-hot encode the 'City/Suburb/Town/Rural 2013' column\n",
    "data = pd.get_dummies(data, columns=['City/Suburb/Town/Rural 2013'], drop_first=True)\n",
    "\n",
    "# Remove commas from numerical values in the DataFrame\n",
    "data = data.replace({',': ''}, regex=True)\n",
    "\n",
    "# Convert dependent variable to numeric and handle errors\n",
    "data['Median_Household_Income_2019'] = pd.to_numeric(data['Median_Household_Income_2019'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in the dependent variable\n",
    "data = data.dropna(subset=['Median_Household_Income_2019'])\n",
    "\n",
    "# Define independent and dependent variables as numpy arrays\n",
    "X = data.drop(columns=['Median_Household_Income_2019']).values\n",
    "y = data['Median_Household_Income_2019'].values\n",
    "\n",
    "# Convert array to float\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)\n",
    "\n",
    "# Identify and replace infinite values with NaN\n",
    "X[~np.isfinite(X)] = np.nan\n",
    "\n",
    "# Impute missing values (NaN) with mean\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "X = mean_imputer.fit_transform(X)\n",
    "\n",
    "# Add constant to independent variables for intercept term\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the OLS model\n",
    "ols_model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print summary of the model\n",
    "print(\"OLS model with reduced dataset:\")\n",
    "print(ols_model.summary())\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "X_df = pd.DataFrame(X, columns=['const'] + list(data.drop(columns=['Median_Household_Income_2019']).columns))\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Variable\"] = X_df.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X_df.values, i) for i in range(X_df.shape[1])]\n",
    "\n",
    "print(\"VIF for reduced dataset:\")\n",
    "print(vif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9008574c-b6cc-47b5-a781-1412567cd4f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model 3: OLS Model with Standardized Dataset\n",
    "** Variables: **\n",
    "\n",
    "Independent Variables:\n",
    "    \n",
    "* 'Less than a high school diploma, 1970'\n",
    "\n",
    "* 'High school diploma only, 1970'\n",
    "\n",
    "* 'City/Suburb/Town/Rural 2013' (one-hot encoded: Rural, Suburb, Town)\n",
    "\n",
    "Dependent Variable:\n",
    "    \n",
    "* 'Median_Household_Income_2019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "409271ee-a419-42be-8ddb-9df807186f66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS model with standardized dataset:\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.217\n",
      "Model:                            OLS   Adj. R-squared:                  0.216\n",
      "Method:                 Least Squares   F-statistic:                     176.4\n",
      "Date:                Sat, 01 Jun 2024   Prob (F-statistic):          4.09e-166\n",
      "Time:                        14:49:53   Log-Likelihood:                -34734.\n",
      "No. Observations:                3193   AIC:                         6.948e+04\n",
      "Df Residuals:                    3187   BIC:                         6.952e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       5.587e+04    227.174    245.956      0.000    5.54e+04    5.63e+04\n",
      "x1         -3.667e+04   4850.831     -7.560      0.000   -4.62e+04   -2.72e+04\n",
      "x2          3.682e+04   4851.243      7.591      0.000    2.73e+04    4.63e+04\n",
      "x3         -6459.5814    254.524    -25.379      0.000   -6958.629   -5960.534\n",
      "x4         -3571.7513    244.187    -14.627      0.000   -4050.530   -3092.973\n",
      "x5         -5199.9710    250.721    -20.740      0.000   -5691.561   -4708.381\n",
      "==============================================================================\n",
      "Omnibus:                      720.712   Durbin-Watson:                   1.214\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2076.975\n",
      "Skew:                           1.169   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.186   Cond. No.                         42.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "VIF for standardized dataset:\n",
      "                                Variable         VIF\n",
      "0                                  const    1.000000\n",
      "1  Less than a high school diploma, 1970  455.948083\n",
      "2         High school diploma only, 1970  456.025669\n",
      "3      City/Suburb/Town/Rural 2013_Rural    1.255282\n",
      "4     City/Suburb/Town/Rural 2013_Suburb    1.155385\n",
      "5       City/Suburb/Town/Rural 2013_Town    1.218045\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Extract relevant columns\n",
    "data = merged_data[['Less than a high school diploma, 1970', \n",
    "                    'High school diploma only, 1970', \n",
    "                    'Median_Household_Income_2019',\n",
    "                    'City/Suburb/Town/Rural 2013']]\n",
    "\n",
    "# One-hot encode the 'City/Suburb/Town/Rural 2013' column\n",
    "data = pd.get_dummies(data, columns=['City/Suburb/Town/Rural 2013'], drop_first=True)\n",
    "\n",
    "# Remove commas from numerical values in the DataFrame\n",
    "data = data.replace({',': ''}, regex=True)\n",
    "\n",
    "# Convert dependent variable to numeric and handle errors\n",
    "data['Median_Household_Income_2019'] = pd.to_numeric(data['Median_Household_Income_2019'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in the dependent variable\n",
    "data = data.dropna(subset=['Median_Household_Income_2019'])\n",
    "\n",
    "# Define independent and dependent variables as numpy arrays\n",
    "X = data.drop(columns=['Median_Household_Income_2019']).values\n",
    "y = data['Median_Household_Income_2019'].values\n",
    "\n",
    "# Convert array to float\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)\n",
    "\n",
    "# Identify and replace infinite values with NaN\n",
    "X[~np.isfinite(X)] = np.nan\n",
    "\n",
    "# Impute missing values (NaN) with mean\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "X = mean_imputer.fit_transform(X)\n",
    "\n",
    "# Standardize the independent variables\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Add constant to independent variables for intercept term\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the OLS model\n",
    "ols_model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print summary of the model\n",
    "print(\"OLS model with standardized dataset:\")\n",
    "print(ols_model.summary())\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "X_df = pd.DataFrame(X, columns=['const'] + list(data.drop(columns=['Median_Household_Income_2019']).columns))\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Variable\"] = X_df.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X_df.values, i) for i in range(X_df.shape[1])]\n",
    "\n",
    "print(\"VIF for standardized dataset:\")\n",
    "print(vif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5e7805-1344-432d-a49b-667d199567f8",
   "metadata": {},
   "source": [
    "## Task 3 (Analysis already done for Task 3 & 4 under Task 2)\n",
    "\n",
    "Consider all of the regression assumptions that must be met, do any transformations you deem necessary, and then refit the model. Interpret the regression results (explain assumptions that are broken) and provide an answer to the question of \"how does education level attained influence household income in rural vs urban communities\".\n",
    "\n",
    "Also, provide an answer in layman's terms that you could report to stakeholders that may or may not be familiar with regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72657380-a57b-462d-b919-898b3dd88aa8",
   "metadata": {},
   "source": [
    "\n",
    "This research indicates that education level and community type play a significant role in determining household income.\n",
    "\n",
    "**The coefficients for education levels indicate:**\n",
    "* Having less than a high school diploma is associated with a decrease in household income.\n",
    "* Having a high school diploma only is associated with an increase in household income compared to having less than a high school diploma.\n",
    "\n",
    "**Community Type:**\n",
    "* Rural areas are associated with lower household incomes compared to urban areas.\n",
    "* Suburban and town areas also show lower household incomes, but the effect is less pronounced than in rural areas. \n",
    "\n",
    "This suggests that both education and location are important factors in determining household income.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed39e5e7-de02-4eb5-8fac-778b6c9b5c5b",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "Repeat the above analysis but with unemployment rate as the response variable. Answer the same questions you did in Task 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da384f6-a3a7-44b9-9799-cf534ae3daaa",
   "metadata": {},
   "source": [
    "Our analysis indicates that education levels and community types also impact unemployment rates. Individuals with lower education levels tend to have higher unemployment rates. Similarly, those living in rural areas face higher unemployment rates compared to urban areas. These findings suggest that improving education and providing more economic opportunities in rural areas could help reduce unemployment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
