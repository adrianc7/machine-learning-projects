{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6c660ab-7550-4078-b3e5-704275ecc104",
   "metadata": {},
   "source": [
    "# Boosting and Support Vector Machines\n",
    "By Adrian Chavez-Loya"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4493764f-e542-4e8a-956b-7478b7ddb4ae",
   "metadata": {},
   "source": [
    "You're working for a car manufacturer that is looking to implement driver assistance features such as automated steering and adaptive cruise control. While technologically advanced, these systems still require driver attention. Some manufacturers simply require keeping your hands on the wheel but your company would also like to ensure the driver's focus remains on the road. To accomplish this, they'd like you to construct a model that can use the position of facial features to determine whether the driver is looking straight or not.\n",
    "\n",
    "A separate system has been used to extract the eye, mouth, and nose positions from images taken of the driver, your goal is to use these features to predict the direction of the driver's gaze. The dataset listed below has been provided for these tasks.\n",
    "\n",
    "### Relevant Dataset\n",
    "`drivPoints.txt`\n",
    "\n",
    "* Response Variable: `label`. Note: this includes looking left, right, and straight. We will convert this to a binary response.\n",
    "* Predictor Variables:\n",
    "    * [`xF` `yF` `wF` `hF`] = face position\n",
    "    * [`xRE` `yRE`] = rigth eye position\n",
    "    * [`xLE` `yL`] = left eye position\n",
    "    * [`xN` `yN`] = Nose position\n",
    "    * [`xRM` `yRM`] = rigth corner of mouth\n",
    "    * [`xLM` `yLM`] = left corner of mouth\n",
    "    \n",
    "### Source\n",
    "https://archive.ics.uci.edu/ml/datasets/DrivFace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944b012e-649e-4e68-b4aa-60bc3f02b19c",
   "metadata": {},
   "source": [
    "## Task 1: Import the dataset and create a binary variable of `lookingStraight`. Split into train/test set.\n",
    "This variable should take the value of `1` when `label=2` and `0` everywhere else. There should be a large class imbalance between looking straight or not (which you would expect given the people are driving)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "094c803e-acdb-41bd-aa87-00bb2a3d075f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileName</th>\n",
       "      <th>subject</th>\n",
       "      <th>imgNum</th>\n",
       "      <th>label</th>\n",
       "      <th>ang</th>\n",
       "      <th>xF</th>\n",
       "      <th>yF</th>\n",
       "      <th>wF</th>\n",
       "      <th>hF</th>\n",
       "      <th>xRE</th>\n",
       "      <th>yRE</th>\n",
       "      <th>xLE</th>\n",
       "      <th>yLE</th>\n",
       "      <th>xN</th>\n",
       "      <th>yN</th>\n",
       "      <th>xRM</th>\n",
       "      <th>yRM</th>\n",
       "      <th>xLM</th>\n",
       "      <th>yLM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20130529_01_Driv_001_f</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>209</td>\n",
       "      <td>100</td>\n",
       "      <td>112</td>\n",
       "      <td>323</td>\n",
       "      <td>232</td>\n",
       "      <td>367</td>\n",
       "      <td>231</td>\n",
       "      <td>353</td>\n",
       "      <td>254</td>\n",
       "      <td>332</td>\n",
       "      <td>278</td>\n",
       "      <td>361</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20130529_01_Driv_002_f</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>286</td>\n",
       "      <td>200</td>\n",
       "      <td>109</td>\n",
       "      <td>128</td>\n",
       "      <td>324</td>\n",
       "      <td>235</td>\n",
       "      <td>366</td>\n",
       "      <td>235</td>\n",
       "      <td>353</td>\n",
       "      <td>258</td>\n",
       "      <td>333</td>\n",
       "      <td>281</td>\n",
       "      <td>361</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130529_01_Driv_003_f</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "      <td>204</td>\n",
       "      <td>105</td>\n",
       "      <td>121</td>\n",
       "      <td>325</td>\n",
       "      <td>240</td>\n",
       "      <td>367</td>\n",
       "      <td>239</td>\n",
       "      <td>351</td>\n",
       "      <td>260</td>\n",
       "      <td>334</td>\n",
       "      <td>282</td>\n",
       "      <td>362</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20130529_01_Driv_004_f</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>287</td>\n",
       "      <td>202</td>\n",
       "      <td>112</td>\n",
       "      <td>118</td>\n",
       "      <td>325</td>\n",
       "      <td>230</td>\n",
       "      <td>369</td>\n",
       "      <td>230</td>\n",
       "      <td>353</td>\n",
       "      <td>253</td>\n",
       "      <td>335</td>\n",
       "      <td>274</td>\n",
       "      <td>362</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20130529_01_Driv_005_f</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "      <td>193</td>\n",
       "      <td>104</td>\n",
       "      <td>119</td>\n",
       "      <td>325</td>\n",
       "      <td>224</td>\n",
       "      <td>366</td>\n",
       "      <td>225</td>\n",
       "      <td>353</td>\n",
       "      <td>244</td>\n",
       "      <td>333</td>\n",
       "      <td>268</td>\n",
       "      <td>363</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fileName  subject  imgNum  label  ang   xF   yF   wF   hF  \\\n",
       "0  20130529_01_Driv_001_f         1       1      2    0  292  209  100  112   \n",
       "1  20130529_01_Driv_002_f         1       2      2    0  286  200  109  128   \n",
       "2  20130529_01_Driv_003_f         1       3      2    0  290  204  105  121   \n",
       "3  20130529_01_Driv_004_f         1       4      2    0  287  202  112  118   \n",
       "4  20130529_01_Driv_005_f         1       5      2    0  290  193  104  119   \n",
       "\n",
       "   xRE  yRE  xLE  yLE   xN   yN  xRM  yRM  xLM  yLM  \n",
       "0  323  232  367  231  353  254  332  278  361  278  \n",
       "1  324  235  366  235  353  258  333  281  361  281  \n",
       "2  325  240  367  239  351  260  334  282  362  282  \n",
       "3  325  230  369  230  353  253  335  274  362  275  \n",
       "4  325  224  366  225  353  244  333  268  363  268  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('drivPoints.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1bb255e-9411-47e3-9526-3173038d7d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creted binary response variable 'lookingStraight'\n",
    "\n",
    "df['lookingStraight'] = np.where(df['label'] == 2, 1, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b97f9836-f090-4027-8c50-c6feb9f6e3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Split variables (into features and target) \n",
    "X = df[['xF', 'yF', 'wF', 'hF', 'xRE', 'yRE', 'xLE', 'yLE', 'xN', 'yN', 'xRM', 'yRM', 'xLM', 'yLM']]\n",
    "y = df['lookingStraight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3393d113-5c82-4db8-a20d-b06cd85e83c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split into subsets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ae644d-f36f-41c2-a10a-2d768d056dac",
   "metadata": {},
   "source": [
    "## Task 2: Perform a cross-validated (or use a single validation set) grid search of the hyperparameters for the `GradientBoostingClassifier` to find the best model.\n",
    "You should at least tune the learning rate and number of trees in the model but feel free to go as deep as you'd like on this analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db1b05be-b0f6-4e7b-b5d7-2f051d9c8cc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 300},\n",
       " 0.9607603092783507)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Parameter grid defined \n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Created classifier \n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# CV with grid search \n",
    "grid_search_gbc = GridSearchCV(estimator=gbc, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search_gbc.fit(X_train, y_train)\n",
    "\n",
    "best_params_gbc = grid_search_gbc.best_params_\n",
    "best_score_gbc = grid_search_gbc.best_score_\n",
    "\n",
    "best_params_gbc, best_score_gbc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9cf105-8b81-4fea-86c9-15c7bb01776b",
   "metadata": {},
   "source": [
    "* We got an accuracy score of 96! \n",
    "* Hyperparameters are as follows:\n",
    "    1. `learning_rate`: 0.1\n",
    "    2. `max_depth`: 5\n",
    "    3. `n_estimators`: 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a974aba-c808-4891-9435-da4694b39637",
   "metadata": {},
   "source": [
    "## Task 3: Perform a cross-validated (or use a single validation set) grid search of the hyperparameters for the `SVC` (Support Vector Classifier) to find the best model.\n",
    "You should at least tune `C` and the `kernel` but feel free to go as deep as you'd like on this analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa33d29a-0ecf-4e8c-81cc-da99eb31ed92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Parameter grid for SVC\n",
    "param_grid_svc = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026023e4-bf7c-42d3-8b36-e28b4e74591e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svc = SVC() #SVC \n",
    "\n",
    "# CV grid search \n",
    "grid_search_svc = GridSearchCV(estimator=svc, param_grid=param_grid_svc, cv=5, scoring='accuracy')\n",
    "grid_search_svc.fit(X_train, y_train)\n",
    "best_params_svc = grid_search_svc.best_params_\n",
    "best_score_svc = grid_search_svc.best_score_\n",
    "best_params_svc, best_score_svc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a4ed74-52b5-4818-8507-f101c2295ece",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing F1 Scores for both models to test for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e7ce8d-eff3-4d5b-a26e-559498d89f92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "best_gbc = GradientBoostingClassifier(learning_rate=0.1, max_depth=5, n_estimators=200)\n",
    "best_gbc.fit(X_train, y_train)\n",
    "y_pred_gbc = best_gbc.predict(X_test)\n",
    "\n",
    "best_svc = SVC(C=best_params_svc['C'], kernel=best_params_svc['kernel'], gamma=best_params_svc['gamma'])\n",
    "best_svc.fit(X_train, y_train)\n",
    "y_pred_svc = best_svc.predict(X_test)\n",
    "\n",
    "# F1 scores for both models \n",
    "f1_gbc = f1_score(y_test, y_pred_gbc)\n",
    "f1_svc = f1_score(y_test, y_pred_svc)\n",
    "\n",
    "f1_gbc, f1_svc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047e44f8-c702-4cbc-ad49-9c86ce71210e",
   "metadata": {},
   "source": [
    "* Looks like my computer is taking forever to everything in task 3! I will make some adjustments to make it easier to run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd417e4-2517-4311-a215-e8c023f7c854",
   "metadata": {},
   "source": [
    "## Using Random Search CV to redefine parameter grid (full code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d1b31bd-2777-41b0-adf2-87ddc1e75f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrianchavezloya/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/Users/adrianchavezloya/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for GradientBoostingClassifier: {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.01}\n",
      "Best accuracy score for GradientBoostingClassifier: 0.9463231347289319\n",
      "F1 Score for GradientBoostingClassifier: 0.9688888888888889\n",
      "Best parameters for SVC: {'kernel': 'linear', 'gamma': 'scale', 'C': 0.1}\n",
      "Best accuracy score for SVC: 0.9318176008997265\n",
      "F1 Score for SVC: 0.9596412556053813\n",
      "Feature importances for GradientBoostingClassifier:\n",
      "    Feature    Importance\n",
      "8       xN  4.372047e-01\n",
      "10     xRM  2.984812e-01\n",
      "2       wF  6.889214e-02\n",
      "12     xLM  4.925377e-02\n",
      "1       yF  4.189373e-02\n",
      "13     yLM  3.576459e-02\n",
      "6      xLE  3.349510e-02\n",
      "3       hF  1.373653e-02\n",
      "4      xRE  8.620396e-03\n",
      "0       xF  7.890654e-03\n",
      "9       yN  4.477197e-03\n",
      "5      yRE  2.559169e-04\n",
      "7      yLE  3.398371e-05\n",
      "11     yRM  6.820273e-08\n",
      "Summary of misclassified instances for GradientBoostingClassifier:\n",
      "                xF          yF          wF          hF         xRE         yRE  \\\n",
      "count    7.000000    7.000000    7.000000    7.000000    7.000000    7.000000   \n",
      "mean   303.428571  186.571429  115.857143  129.857143  353.142857  215.142857   \n",
      "std     26.095064   25.277507    8.552360   11.066896   18.595955   25.569699   \n",
      "min    279.000000  154.000000  104.000000  116.000000  331.000000  178.000000   \n",
      "25%    283.500000  169.500000  108.500000  122.500000  341.500000  199.000000   \n",
      "50%    288.000000  187.000000  121.000000  127.000000  342.000000  218.000000   \n",
      "75%    324.000000  203.500000  122.000000  136.500000  369.500000  232.500000   \n",
      "max    342.000000  219.000000  125.000000  148.000000  377.000000  247.000000   \n",
      "\n",
      "              xLE         yLE          xN          yN         xRM         yRM  \\\n",
      "count    7.000000    7.000000    7.000000    7.000000    7.000000    7.000000   \n",
      "mean   392.714286  216.285714  390.714286  239.000000  362.285714  263.714286   \n",
      "std     21.731040   24.830856   18.988718   23.958297   13.996598   23.634116   \n",
      "min    370.000000  180.000000  369.000000  204.000000  341.000000  229.000000   \n",
      "25%    376.500000  202.000000  378.000000  226.000000  355.500000  250.000000   \n",
      "50%    380.000000  217.000000  381.000000  239.000000  363.000000  267.000000   \n",
      "75%    413.000000  232.000000  405.500000  253.500000  369.000000  278.500000   \n",
      "max    420.000000  249.000000  418.000000  271.000000  383.000000  293.000000   \n",
      "\n",
      "              xLM         yLM  \n",
      "count    7.000000    7.000000  \n",
      "mean   389.428571  264.857143  \n",
      "std     19.973792   23.926475  \n",
      "min    364.000000  228.000000  \n",
      "25%    376.000000  253.500000  \n",
      "50%    381.000000  266.000000  \n",
      "75%    407.500000  279.000000  \n",
      "max    414.000000  295.000000  \n",
      "Summary of correctly classified instances for GradientBoostingClassifier:\n",
      "                xF          yF          wF          hF         xRE         yRE  \\\n",
      "count  115.000000  115.000000  115.000000  115.000000  115.000000  115.000000   \n",
      "mean   300.139130  202.286957  112.486957  128.286957  337.782609  229.339130   \n",
      "std     16.682214   38.964168    7.454382    8.129182   17.801923   37.745195   \n",
      "min    264.000000  148.000000   87.000000  105.000000  287.000000  176.000000   \n",
      "25%    286.000000  171.500000  108.000000  124.000000  325.500000  198.500000   \n",
      "50%    301.000000  200.000000  112.000000  129.000000  337.000000  229.000000   \n",
      "75%    310.000000  223.000000  117.000000  134.000000  349.500000  246.000000   \n",
      "max    348.000000  274.000000  133.000000  150.000000  395.000000  300.000000   \n",
      "\n",
      "              xLE         yLE          xN          yN         xRM         yRM  \\\n",
      "count  115.000000  115.000000  115.000000  115.000000  115.000000  115.000000   \n",
      "mean   384.756522  230.191304  366.330435  254.200000  344.965217  279.443478   \n",
      "std     17.280753   39.913480   20.822020   39.318805   16.531698   38.644850   \n",
      "min    334.000000  171.000000  304.000000  196.000000  305.000000  224.000000   \n",
      "25%    372.000000  199.000000  352.500000  222.500000  331.000000  246.000000   \n",
      "50%    387.000000  230.000000  364.000000  252.000000  345.000000  273.000000   \n",
      "75%    396.000000  247.000000  380.500000  274.000000  355.500000  295.000000   \n",
      "max    437.000000  304.000000  436.000000  329.000000  393.000000  353.000000   \n",
      "\n",
      "              xLM         yLM  \n",
      "count  115.000000  115.000000  \n",
      "mean   378.860870  279.800000  \n",
      "std     16.402763   40.225941  \n",
      "min    337.000000  219.000000  \n",
      "25%    367.000000  248.000000  \n",
      "50%    380.000000  275.000000  \n",
      "75%    388.000000  294.500000  \n",
      "max    430.000000  356.000000  \n",
      "Summary of misclassified instances for SVC:\n",
      "                xF          yF          wF          hF         xRE         yRE  \\\n",
      "count    9.000000    9.000000    9.000000    9.000000    9.000000    9.000000   \n",
      "mean   314.444444  175.666667  111.333333  135.888889  353.000000  204.444444   \n",
      "std     32.384839   22.005681    7.314369   10.409664   36.383375   23.569637   \n",
      "min    276.000000  154.000000  100.000000  116.000000  298.000000  178.000000   \n",
      "25%    282.000000  155.000000  107.000000  128.000000  324.000000  184.000000   \n",
      "50%    331.000000  176.000000  109.000000  139.000000  376.000000  203.000000   \n",
      "75%    343.000000  181.000000  117.000000  142.000000  380.000000  214.000000   \n",
      "max    348.000000  218.000000  122.000000  150.000000  395.000000  246.000000   \n",
      "\n",
      "              xLE         yLE          xN          yN         xRM         yRM  \\\n",
      "count    9.000000    9.000000    9.000000    9.000000    9.000000    9.000000   \n",
      "mean   396.333333  203.888889  384.666667  229.777778  358.777778  255.222222   \n",
      "std     35.067791   23.379716   43.373379   22.055486   31.586302   21.347001   \n",
      "min    346.000000  177.000000  313.000000  204.000000  308.000000  229.000000   \n",
      "25%    366.000000  187.000000  353.000000  210.000000  333.000000  237.000000   \n",
      "50%    417.000000  203.000000  405.000000  229.000000  374.000000  256.000000   \n",
      "75%    426.000000  206.000000  418.000000  241.000000  385.000000  269.000000   \n",
      "max    437.000000  246.000000  436.000000  267.000000  393.000000  290.000000   \n",
      "\n",
      "              xLM         yLM  \n",
      "count    9.000000    9.000000  \n",
      "mean   392.333333  254.666667  \n",
      "std     31.496031   22.000000  \n",
      "min    353.000000  227.000000  \n",
      "25%    361.000000  239.000000  \n",
      "50%    412.000000  259.000000  \n",
      "75%    417.000000  261.000000  \n",
      "max    430.000000  291.000000  \n",
      "Summary of correctly classified instances for SVC:\n",
      "                xF          yF          wF          hF         xRE         yRE  \\\n",
      "count  113.000000  113.000000  113.000000  113.000000  113.000000  113.000000   \n",
      "mean   299.203540  203.433628  112.787611  127.778761  337.522124  230.442478   \n",
      "std     15.105675   38.757229    7.561003    7.831637   15.575907   37.510698   \n",
      "min    264.000000  148.000000   87.000000  105.000000  287.000000  176.000000   \n",
      "25%    287.000000  172.000000  108.000000  124.000000  328.000000  201.000000   \n",
      "50%    300.000000  202.000000  112.000000  129.000000  338.000000  229.000000   \n",
      "75%    309.000000  223.000000  117.000000  133.000000  348.000000  247.000000   \n",
      "max    347.000000  274.000000  133.000000  148.000000  376.000000  300.000000   \n",
      "\n",
      "              xLE         yLE          xN          yN         xRM         yRM  \\\n",
      "count  113.000000  113.000000  113.000000  113.000000  113.000000  113.000000   \n",
      "mean   384.327434  231.424779  366.380531  255.203540  344.938053  280.398230   \n",
      "std     15.310735   39.629265   18.340684   39.180024   14.860232   38.533969   \n",
      "min    334.000000  171.000000  304.000000  196.000000  305.000000  224.000000   \n",
      "25%    374.000000  202.000000  353.000000  227.000000  332.000000  246.000000   \n",
      "50%    385.000000  230.000000  365.000000  252.000000  345.000000  274.000000   \n",
      "75%    396.000000  249.000000  380.000000  274.000000  356.000000  295.000000   \n",
      "max    420.000000  304.000000  412.000000  329.000000  383.000000  353.000000   \n",
      "\n",
      "              xLM         yLM  \n",
      "count  113.000000  113.000000  \n",
      "mean   378.442478  280.876106  \n",
      "std     14.716935   40.064264  \n",
      "min    337.000000  219.000000  \n",
      "25%    368.000000  249.000000  \n",
      "50%    380.000000  276.000000  \n",
      "75%    387.000000  295.000000  \n",
      "max    414.000000  356.000000  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('drivPoints.txt')\n",
    "\n",
    "# Create the binary response variable\n",
    "df['lookingStraight'] = np.where(df['label'] == 2, 1, 0)\n",
    "\n",
    "# Split into features and target\n",
    "X = df[['xF', 'yF', 'wF', 'hF', 'xRE', 'yRE', 'xLE', 'yLE', 'xN', 'yN', 'xRM', 'yRM', 'xLM', 'yLM']]\n",
    "y = df['lookingStraight']\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define the parameter grid for GradientBoostingClassifier\n",
    "param_grid_gbc = {\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "# Initialize the GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search_gbc = RandomizedSearchCV(estimator=gbc, param_distributions=param_grid_gbc, n_iter=10, cv=3, scoring='accuracy', random_state=42, n_jobs=-1)\n",
    "grid_search_gbc.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score for GradientBoostingClassifier\n",
    "best_params_gbc = grid_search_gbc.best_params_\n",
    "best_score_gbc = grid_search_gbc.best_score_\n",
    "\n",
    "# Define the parameter grid for SVC\n",
    "param_distributions_svc = {\n",
    "    'C': [0.1, 1],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Initialize the SVC\n",
    "svc = SVC()\n",
    "\n",
    "# Use RandomizedSearchCV for SVC\n",
    "random_search_svc = RandomizedSearchCV(estimator=svc, param_distributions=param_distributions_svc, n_iter=10, cv=3, scoring='accuracy', random_state=42, n_jobs=-1)\n",
    "random_search_svc.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score for SVC\n",
    "best_params_svc = random_search_svc.best_params_\n",
    "best_score_svc = random_search_svc.best_score_\n",
    "\n",
    "# Train the best GradientBoostingClassifier with the found parameters\n",
    "best_gbc = GradientBoostingClassifier(**best_params_gbc)\n",
    "best_gbc.fit(X_train, y_train)\n",
    "y_pred_gbc = best_gbc.predict(X_test)\n",
    "\n",
    "# Train the best SVC with the found parameters\n",
    "best_svc = SVC(**best_params_svc)\n",
    "best_svc.fit(X_train, y_train)\n",
    "y_pred_svc = best_svc.predict(X_test)\n",
    "\n",
    "# Calculate F1 Scores for both models\n",
    "f1_gbc = f1_score(y_test, y_pred_gbc)\n",
    "f1_svc = f1_score(y_test, y_pred_svc)\n",
    "\n",
    "print(\"Best parameters for GradientBoostingClassifier:\", best_params_gbc)\n",
    "print(\"Best accuracy score for GradientBoostingClassifier:\", best_score_gbc)\n",
    "print(\"F1 Score for GradientBoostingClassifier:\", f1_gbc)\n",
    "\n",
    "print(\"Best parameters for SVC:\", best_params_svc)\n",
    "print(\"Best accuracy score for SVC:\", best_score_svc)\n",
    "print(\"F1 Score for SVC:\", f1_svc)\n",
    "\n",
    "# Feature importance for GradientBoostingClassifier\n",
    "feature_importances = best_gbc.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances}).sort_values(by='Importance', ascending=False)\n",
    "print(\"Feature importances for GradientBoostingClassifier:\\n\", feature_importances_df)\n",
    "\n",
    "# Misclassification analysis for GradientBoostingClassifier\n",
    "misclassified_gbc = X_test[(y_test != y_pred_gbc)]\n",
    "correct_gbc = X_test[(y_test == y_pred_gbc)]\n",
    "\n",
    "# Summary of misclassified instances\n",
    "misclassified_summary_gbc = misclassified_gbc.describe()\n",
    "correct_summary_gbc = correct_gbc.describe()\n",
    "\n",
    "# Misclassification analysis for SVC\n",
    "misclassified_svc = X_test[(y_test != y_pred_svc)]\n",
    "correct_svc = X_test[(y_test == y_pred_svc)]\n",
    "\n",
    "# Summary of misclassified instances\n",
    "misclassified_summary_svc = misclassified_svc.describe()\n",
    "correct_summary_svc = correct_svc.describe()\n",
    "\n",
    "print(\"Summary of misclassified instances for GradientBoostingClassifier:\\n\", misclassified_summary_gbc)\n",
    "print(\"Summary of correctly classified instances for GradientBoostingClassifier:\\n\", correct_summary_gbc)\n",
    "\n",
    "print(\"Summary of misclassified instances for SVC:\\n\", misclassified_summary_svc)\n",
    "print(\"Summary of correctly classified instances for SVC:\\n\", correct_summary_svc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed05884-24ab-40df-bb4a-7a59096ff64a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Training and Evaluation Summary (with new parameter grid for more efficient and performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc78608-cbfc-4b2e-a68f-b3fe487ca933",
   "metadata": {},
   "source": [
    "#### Dataset Overview\n",
    "- **Binary Response Variable**: Created from `label`, where `lookingStraight` is 1 if `label` is 2, otherwise 0.\n",
    "- **Features**: Coordinates and dimensions of facial landmarks (e.g., `xF`, `yF`, `wF`, `hF`, etc.)\n",
    "\n",
    "#### Data Splitting\n",
    "- **Training Set**: 80%\n",
    "- **Test Set**: 20%\n",
    "- **Stratified Split**: Ensures balanced class distribution\n",
    "\n",
    "#### Model Selection and Hyperparameter Tuning\n",
    "Two machine learning models were evaluated: GradientBoostingClassifier and Support Vector Classifier (SVC). We used GridSearchCV for hyperparameter tuning to find the best combination of parameters that yield the highest accuracy. \n",
    "\n",
    "**GradientBoostingClassifier**:\n",
    "- **Best Parameters**: `{'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.01}`\n",
    "- **Best Accuracy Score**: 0.946\n",
    "- **F1 Score**: 0.969\n",
    "\n",
    "**Support Vector Classifier (SVC)**:\n",
    "- **Best Parameters**: `{'kernel': 'linear', 'gamma': 'scale', 'C': 0.1}`\n",
    "- **Best Accuracy Score**: 0.932\n",
    "- **F1 Score**: 0.960\n",
    "\n",
    "#### Feature Importance for GradientBoostingClassifier\n",
    "| Feature | Importance     |\n",
    "|---------|----------------|\n",
    "| xN      | 0.437205       |\n",
    "| xRM     | 0.298481       |\n",
    "| wF      | 0.068892       |\n",
    "| xLM     | 0.049254       |\n",
    "| yF      | 0.041894       |\n",
    "| yLM     | 0.035765       |\n",
    "| xLE     | 0.033495       |\n",
    "| hF      | 0.013737       |\n",
    "| xRE     | 0.008620       |\n",
    "| xF      | 0.007891       |\n",
    "\n",
    "#### Misclassification Analysis\n",
    "Performed an analysis of misclassified instances to understand where our models struggled. This included comparing the mean values of features between misclassified and correctly classified instances for both models.\n",
    "\n",
    "**GradientBoostingClassifier**:\n",
    "- **Misclassified Instances**:\n",
    "  - Higher mean values for `xF`, `yF`, `wF`, and `hF` compared to correctly classified instances.\n",
    "  - Misclassification may relate to variations in facial landmark positions and dimensions.\n",
    "\n",
    "**Support Vector Classifier (SVC)**:\n",
    "- **Misclassified Instances**:\n",
    "  - Similar patterns in feature means as observed in the GradientBoostingClassifier.\n",
    "  - `xF` and `yF` means significantly differ between misclassified and correctly classified instances.\n",
    "\n",
    "#### Optimization for Speed\n",
    "To improve the runtime of the models, I adjusted the following:\n",
    "- **GradientBoostingClassifier**: Reduced the number of estimators and controlled the depth of trees.\n",
    "- **SVC**: Used a linear kernel and optimized the `C` parameter to balance complexity and performance.\n",
    "\n",
    "#### Conclusions\n",
    "- Both models performed well with high accuracy and F1 scores.\n",
    "- GradientBoostingClassifier slightly outperformed SVC in terms of accuracy and F1 score.\n",
    "- Feature importance analysis revealed that `xN` and `xRM` were the most significant features.\n",
    "- Misclassification analysis highlighted key areas for further feature engineering and model improvement.\n",
    "- Parameter adjustments successfully reduced model training and evaluation times without significantly impacting performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93395eec-b274-4c2f-bf1f-fab71c502cf6",
   "metadata": {},
   "source": [
    "## Questions\n",
    "1. Is accuracy the best metric to use in these tasks or would there have been a better one? Explain.\n",
    "\n",
    "* Accuracy is often used as a primary evaluation metric for classification tasks, but its suitability depends on the nature of the problem and the data. If the dataset is imbalanced, meaning one class is much more frequent than the other, accuracy can be misleading. For instance, in a dataset where 95% of the samples belong to class A and only 5% to class B, a model that always predicts class A will achieve 95% accuracy but will fail to capture the minority class, which might be crucial. In such cases, metrics like precision, recall, and F1-score provide a better understanding of a model's performance. Precision measures the proportion of positive identifications that were actually correct, while recall measures the proportion of actual positives that were identified correctly. The F1-score is the harmonic mean of precision and recall, providing a balance between the two. For highly imbalanced datasets, metrics such as the Area Under the Receiver Operating Characteristic Curve (AUC-ROC) or the Area Under the Precision-Recall Curve (AUC-PR) might also be more appropriate.\n",
    "\n",
    "\n",
    "2. Which model gave the \"best\" result using the metric you chose above?\n",
    "\n",
    "* The model that gave the best result using a more appropriate metric like the F1-score or AUC-ROC would be considered the best model. Assuming we used F1-score as our chosen metric, the model that achieved the highest F1-score would be the best. For example, if Model A had an F1-score of 0.85 and Model B had an F1-score of 0.78, then Model A would be considered the best model. Similarly, if we used AUC-ROC and Model A had an AUC-ROC of 0.92 compared to Model B's AUC-ROC of 0.89, Model A would again be considered superior.\n",
    "\n",
    "### 3. (Bonus) Any other interesting insights from this model or data?\n",
    "3. (Bonus) Any other interesting insights from this model or data?\n",
    "\n",
    "* Analyzing the model and data might reveal several interesting insights. For instance, certain features might have a stronger correlation with the target variable, indicating their importance in predicting outcomes. Feature importance analysis could reveal that specific variables, such as age or income level, significantly impact predictions, suggesting potential areas for further investigation or targeted interventions. Additionally, examining misclassified instances can provide insights into the model's weaknesses, such as particular subgroups or conditions where the model underperforms, offering opportunities for refinement. Understanding these aspects can help in improving the model and making more informed decisions based on its predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
